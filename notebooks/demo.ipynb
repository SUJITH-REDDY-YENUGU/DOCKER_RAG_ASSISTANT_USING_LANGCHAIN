{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b3c93c0",
   "metadata": {},
   "source": [
    "# Docker RAG Assistant Demo\n",
    "\n",
    "This notebook explains the flow of our Retrieval-Augmented Generation (RAG) pipeline\n",
    "for answering questions about Docker documentation.  \n",
    "All collected Docker docs are stored as `.txt` files inside the `notebooks/raw/` folder.\n",
    "\n",
    "---\n",
    "\n",
    "## Step 1: Load Docker Documentation\n",
    "\n",
    "We collected Docker documentation pages from the official site and saved them as `.txt` files.\n",
    "These files are read into memory and tagged with their filenames as metadata, so answers can cite sources.\n",
    "\n",
    "---\n",
    "\n",
    "## Step 2: Chunk Documents\n",
    "\n",
    "The text files are split into smaller sections (chunks) of ~500 characters with overlap.\n",
    "This makes retrieval more efficient and ensures context is preserved.\n",
    "\n",
    "---\n",
    "\n",
    "## Step 3: Create Embeddings\n",
    "\n",
    "Each chunk is converted into a vector representation using the HuggingFace model\n",
    "`sentence-transformers/all-MiniLM-L6-v2`.  \n",
    "These embeddings capture semantic meaning for better search.\n",
    "\n",
    "---\n",
    "\n",
    "## Step 4: Store in ChromaDB\n",
    "\n",
    "The embeddings are stored in a ChromaDB vector database.  \n",
    "This allows semantic search over the documentation.\n",
    "\n",
    "---\n",
    "\n",
    "## Step 5: Retrieval\n",
    "\n",
    "When a user asks a question, the system searches ChromaDB for the most relevant chunks.\n",
    "The retrieved chunks include both the text and the source filename.\n",
    "\n",
    "---\n",
    "\n",
    "## Step 6: Answer Generation\n",
    "\n",
    "The retrieved chunks are passed to the Groq LLM (`llama-3.1-8b-instant`).\n",
    "The model generates a clear answer, grounded in the retrieved documentation,\n",
    "and cites the source `.txt` files.\n",
    "\n",
    "---\n",
    "\n",
    "## Example Q&A\n",
    "\n",
    "**Q:** What is Docker volume?  \n",
    "**A:** A Docker volume persists data outside the lifecycle of a container.  \n",
    "It can be shared across containers and remains even when a container is removed.  \n",
    "**Sources:** `docker_volume_overview.txt`, `docker_bind_mounts.txt`\n",
    "\n",
    "---\n",
    "\n",
    "**Q:** How does the VOLUME instruction in a Dockerfile work?  \n",
    "**A:** The `VOLUME` instruction creates a mount point inside the container and marks it\n",
    "for external volumes so data written there is persisted outside the container layer.  \n",
    "**Sources:** `dockerfile_reference.txt`\n",
    "\n",
    "---\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "This flow demonstrates how the Docker RAG Assistant ingests documentation,\n",
    "creates embeddings, stores them in ChromaDB, retrieves relevant chunks,\n",
    "and generates answers with citations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
